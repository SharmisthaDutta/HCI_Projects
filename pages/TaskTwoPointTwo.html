<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Task 2.2: Usage Scenarios</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link href="../css/css/bootstrap.min.css" rel="stylesheet" type="text/css" media="all">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Droid+Serif|Lobster"/>
    <link rel="stylesheet" href="../css/main.css"/>
</head>
<body>

<h1>Task 2.2: Usage Scenarios</h1>
<div class="container">
    <h3>Candidate Applications</h3>
    <ol>
        <li>Optimize coffee shop order taking and inventory management: design space already occupied by commercial
            tools
        </li>
        <li>Infer emotional state of a child on a car trip and alert parents: too much research needed on sentiment
            analysis
        </li>
        <li><b>Entertain a child in the back seat of a car trip</b>: difficult to implement if using voice commands but
            interesting
        </li>
    </ol>
    <p>We chose a child educational application (#3) since it offers some degree of design difficulty but we have an
        accessible user population (Benjamin, age 2). In designing the application, we considered that the intent of
        the application was to allow some degree of interaction between a non-driving parent and the child; the
        purpose is not to foster independent play since at the target age (2-3 years old) children have a relatively
        short attention span. While not excluding independent play, the type of cooperative play that involves both
        parent and child and the outside environment (as opposed to the virtual environment of the application) seems
        most educational and offers the longest entertainment value. Since this application is designed for long car
        trips, this is an important design consideration.</p>

    <h3>Scenarios</h3>
    <p>
        The application will roughly consist of identifying various illustrated objects on a screen. Since we would
        like to design for cooperative play, we describe two user personas: 1) the <i>child</i>, 2-3 years of age,
        strapped in a car seat in the back seat of a moving vehicle and holding a computer tablet, and 2) a
        <i>parent</i> or adult relative, sitting in the passenger seat of the vehicle holding a smart phone.</p>
    <ol>
        <li><i>Independent Identification</i>: the application displays an illustration of an object (e.g. car, truck,
            motorcycle, etc.), the child either speaks the name of the object or says, "what is that?", the application
            either replies with a success message (e.g. song?) or replies with the name of the object, the child
            advances
            to the next illustration.
        </li>
        <li><i>Cooperative Identification</i>: the parent chooses an illustration of an object (e.g. car, truck,
            motorcycle, etc.), the child either speaks the name of the object or says, "what is that?", the parent
            speaks to the child explaining the object and answering any questions, the parent marks the object as
            complete and chooses the next illustration.
        </li>
        <li><i>Environment Identification</i>: the application (or parent) chooses an illustration of an object (e.g.
            car, truck, motorcycle, etc.), the child observes the environment outside the vehicle and points at the
            object when (if) identified, the parent marks the object as found, the application (or parent) chooses
            another illustration.
        </li>
    </ol>
    <p>
        Several notes: it seems likely that several implementation details may be a challenge to the application's
        success but a distinct advantage if done correctly. For example, the ability of the application to correctly
        parse a child's speech seems dubious but, if implemented, highly valuable. Also, the ability to pair the
        child's tablet and the parent's phone seems complicated, though very possible, but may involve a significant
        amount of infrastructure work.
    </p>

    <h3>Content Model</h3>
    <ol>
        <li><i>illustration</i>: a picture of a thing, used by the child for identification; should have a simple to
            speak name and possible synonyms as metadata.
        </li>
        <li><i>song</i>: sounds used by the application to indicate successful identification; may include some
            graphical element such as video playback of the singer of the song.
        </li>
    </ol>

    <h3>Control Model</h3>
    <ol>
        <li><i>display</i>: the application or parent chooses what illustration to show on the tablet screen; this
            should be visible for both the parent and child.
        </li>
        <li><i>identify</i>: the child names the illustration; this control action will likely be the most difficult
            to determine if voice activation is used; it will be much easier to implement if the parent assists the
            application in determining whether the child's identification was correct (in fact, this should be included
            as a feature to support the latter scenarios).
        </li>
        <li><i>advance</i>: the child or parent can move to the next illustration; no widget is specified in this
            analysis but right-to-left swiping may make sense (observed in ethnography study).
        </li>
        <li><i>trigger</i>: a successful identification triggers the success song and allows the user to advance.
        </li>
    </ol>

    <img src="../images/model.jpg"
         style="height: 300px; width: auto; display: block; margin-top: 2em; margin-left: auto; margin-right: auto;"/>

    <h3>Performance Metrics</h3>
    <ol>
        <li>given pairing instructions, the adult user must pair the adult and child devices in less than 60 seconds
        </li>
        <li>given minimal instructions, the adult user must select a truck as the next illustration in less than 30
            seconds
        </li>
        <li>given minimal instructions, the adult user must manually identify an illustration in less than 30 seconds
        </li>
        <li>given minimal instructions, the adult user must switch from adult mode to child mode and back in less than
            45 seconds
        </li>
        <li>given an adult demonstrating how to swipe illustrations, the child user must be able to learn to swipe
            illustrations in less than 3 minutes
        </li>
        <li>given an adult demonstrating how to identify an illustration, the child user must be able to learn to
            verbally identify illustrations in less than 5 minutes
        </li>
        <li>the application must parse child user's correct illustration identification (verbal) in under 1 second</li>
        <li>on advance, the application must display the next illustration in less than 0.5 seconds</li>
        <li>on advance, the swipe gesture must follow the finger with lag less than 0.1 second</li>
        <li>adult actions must reflect on the child device in less than 1 second</li>
        <li>on incorrect identification, the application must respond in less than 1 second with a voice message to
            repeat the identification
        </li>
        <li>on correct identification, the application must respond in less than 1 second with a success song</li>
    </ol>

    <h3>Preference Metrics</h3>
    <ol>
        <li>Adult: on a scale of 1-10, rate the ease of setup; expect average > 7</li>
        <li>Adult: on a scale of 1-10, how do you rate the quality of sound of the application, 1 being worst quality
            and 10
            being best quality; expect average > 7
        </li>
        <li>Adult: on a scale of 1-10, how easy was it to navigate to a illustration of your choice, 1 being very
            difficult and 10 being quick and easy; expect average > 7
        </li>
        <li>Adult: would you recommend this application to a friend?; expect 75% yes</li>
        <li>Adult: how much would you be willing to pay for the application; expect average > $3</li>
        <li>Adult: what did you like the best about the voice-enabled application?</li>
        <li>Adult: what did you like the least about the voice-enabled application?</li>
        <li>Adult: do you have any other comments, feature requests, or suggestions?</li>
        <li>Child: how long did the child use the application?; expect average > 30 min</li>
        <li>Child: did the child request the application again in the same car trip?; expect 75% yes</li>
        <li>Child: how many consecutive illustrations did the child attempt?; expect average > 10</li>
    </ol>
</div>

<div class="footer">
    <p>Copyright &copy; 2016 - Sharmistha Dutta & Andrew Brown - All Rights Reserved -</p>
</div>

</body>
</html>